{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating decomposer with parameter data hash cache/data-416d4e19c2176420db77bfcb08a3ff1a8b1ecc0c/start.pkl\n",
      "Creating decomposer with parameter lattice hash cache/correlation-4a8a29339073eba7e83adfb84bec38038b4ed32e/start.pkl\n",
      "Created dataset\n",
      "Got embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished and saving to file\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import src.decorrelate as cluster_model\n",
    "MODEL_NAME = 'EleutherAI/pythia-70m'\n",
    "DATASET_NAME = 'NeelNanda/pile-10k'\n",
    "\n",
    "N_DIMS = 512\n",
    "SEED = 69_420\n",
    " \n",
    "DEBUG = False\n",
    " \n",
    "if DEBUG:\n",
    "    N_DATASIZE = 300\n",
    "    N_BLOCKS = 12\n",
    "    STRING_SIZE_CUTOFF = 200\n",
    "else:\n",
    "    # It gets killed aroun 1_800 idk why. Maybe we have a problem with token truncation somewhere\n",
    "    N_DATASIZE = 3_000\n",
    "# \n",
    "    # N_CLUSTERS_MIN = int(0.5 * N_DIMS)\n",
    "    # N_CLUSTERS_MAX = 10 * N_DIMS\n",
    "    # TODO: DEL ME\n",
    "    N_BLOCKS = 6\n",
    "    STRING_SIZE_CUTOFF = 1_200\n",
    "\n",
    "params = cluster_model.InterpParams(\n",
    "\tlattice_params=cluster_model.LatticeParams(\n",
    "\t\ttop_layer_idx = -1,\n",
    "        max_n_parents = 4\n",
    "\t),\n",
    "    # quantization='4bit',\n",
    "\tseed=SEED,\n",
    "    n_datasize=N_DATASIZE,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    model_name=MODEL_NAME,\n",
    "\tmodel_n_dims=N_DIMS,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    string_size_cutoff=STRING_SIZE_CUTOFF,\n",
    "    quantization='4bit'\n",
    ")\n",
    "\n",
    "decomp = cluster_model.Decomposer(params)\n",
    "decomp.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets just look at the highest cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.49433812, ..., 0.3761467 , 0.43882282,\n",
       "        0.54184486],\n",
       "       [0.        , 1.        , 0.48773998, ..., 0.38884602, 0.40527423,\n",
       "        0.57321223],\n",
       "       [0.46509317, 0.51539929, 1.        , ..., 0.37196671, 0.43882171,\n",
       "        0.54031173],\n",
       "       ...,\n",
       "       [0.45388721, 0.52699675, 0.47706647, ..., 1.        , 0.41510652,\n",
       "        0.56630892],\n",
       "       [0.48119008, 0.49913273, 0.5114459 , ..., 0.37722141, 1.        ,\n",
       "        0.        ],\n",
       "       [0.44769753, 0.53194262, 0.47450225, ..., 0.38776844, 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp.internal_correlations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Up a \"Concept\" Lattice Using Graph Restrictions\n",
    "\n",
    "> TODO: this is for latter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.graph as graph\n",
    "import networkx as nx\n",
    "\n",
    "LAYER = 3\n",
    "\n",
    "G = graph.graph_from_correlations(decomp.internal_correlations[LAYER])\n",
    "MAX_CLIQUE_SIZE = 1_000\n",
    "\n",
    "GG = graph.sparsify_weighted_graph(G, degree_upperbound=400)\n",
    "i = nx.find_cliques(GG)\n",
    "clique = next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from '/home/lev/code/research/ai/lattice_cluster_paths/src/utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src.utils as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# decomp.tune_clique((0.0, clique), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# test_at = 100\n",
    "# GG = graph.sparsify_weighted_graph(G, degree_upperbound=test_at)\n",
    "\n",
    "# cliques = []\n",
    "\n",
    "# for node in range(N_DIMS * 2):\n",
    "#     if node % 50 == 0:\n",
    "#         print(\"On node\", node)\n",
    "#     c_it = nx.find_cliques(GG, nodes=[node])\n",
    "#     c_in_curr = []\n",
    "#     for c in c_it:\n",
    "#         c_in_curr.append(c)\n",
    "#         if len(c_in_curr) > 50:\n",
    "#             break\n",
    "#     cliques += c_in_curr\n",
    "#         # if len(cliques) > 10_000:\n",
    "#         #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.39302223, ..., 0.41651665, 0.40421225,\n",
       "        0.4464732 ],\n",
       "       [0.        , 1.        , 0.42954468, ..., 0.44745615, 0.33309616,\n",
       "        0.58418726],\n",
       "       [0.37108543, 0.47733753, 1.        , ..., 0.38395448, 0.36606731,\n",
       "        0.53831451],\n",
       "       ...,\n",
       "       [0.33878978, 0.42835995, 0.33076601, ..., 1.        , 0.28211922,\n",
       "        0.52123939],\n",
       "       [0.45105037, 0.43746735, 0.43263309, ..., 0.38703506, 1.        ,\n",
       "        0.        ],\n",
       "       [0.27322067, 0.42075636, 0.34889717, ..., 0.39215473, 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp.internal_correlations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT CLIQUES WITH LENGTH [7, 8, 7, 7, 7, 7, 7] [(11.529307184250092, [20, 513, 640, 579, 896, 529, 455]), (15.058768710745676, [20, 513, 640, 579, 896, 529, 703, 466]), (11.756739019134766, [20, 513, 640, 579, 896, 738, 466]), (11.710716922918238, [20, 513, 640, 579, 896, 738, 455]), (11.690480828271927, [20, 513, 640, 579, 672, 466, 529]), (11.6828839827758, [20, 513, 640, 579, 672, 466, 740]), (11.713292920756007, [20, 513, 640, 579, 672, 466, 735])]\n",
      "Got tuned clique [1.0, 1.0, 1.2, 1.4, 0.0, 1.4, 0.8]\n",
      "Got tuned clique [1.0, 1.4, 1.2, 1.4, 0.0, 1.4, 0.0, 0.0]\n",
      "Got tuned clique [1.0, 1.0, 1.2, 1.4, 0.6, 1.4, 0.0]\n",
      "Got tuned clique [1.0, 1.2, 1.2, 1.4, 0.6, 1.6, 1.0]\n",
      "Got tuned clique [1.0, 1.4, 1.2, 1.4, 0.4, 0.4, 1.4]\n",
      "Got tuned clique [1.0, 0.0, 1.2, 1.4, 1.4, 0.8, 0.6]\n",
      "Got tuned clique [0.8, 1.4, 1.0, 1.4, 1.4, 0.0, 1.4]\n",
      "Finished for neuron 2 20\n"
     ]
    }
   ],
   "source": [
    "import src.decorrelate as decc\n",
    "import src.kernel as kernel\n",
    "importlib.reload(decc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(kernel)\n",
    "\n",
    "LAYER = 2\n",
    "NEURON = 20\n",
    "\n",
    "# TODO: we **need** to do something like curr-clique removal so we get more interesting cliques...\n",
    "# Also the per-neuron thing makes no sense...\n",
    "decomp.scores_for_neuron(LAYER, NEURON, degree_upperbound=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
