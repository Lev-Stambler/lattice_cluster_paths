{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating decomposer with parameter data hash cache/data-9ca1a7113cd59c0eaf97b97c20dd15e5b47664cf/start.pkl\n",
      "Creating decomposer with parameter lattice hash cache/correlation-cf1e08d4f095000f1b6688a204d42b7c56a5d436/start.pkl\n",
      "Created dataset\n"
     ]
    }
   ],
   "source": [
    "import src.decorrelate as cluster_model\n",
    "MODEL_NAME = 'EleutherAI/pythia-70m'\n",
    "DATASET_NAME = 'NeelNanda/pile-10k'\n",
    "\n",
    "N_DIMS = 512\n",
    "SEED = 69_420\n",
    " \n",
    "DEBUG = False\n",
    " \n",
    "if DEBUG:\n",
    "    N_DATASIZE = 300\n",
    "    N_BLOCKS = 12\n",
    "    STRING_SIZE_CUTOFF = 200\n",
    "else:\n",
    "    # It gets killed aroun 1_800 idk why. Maybe we have a problem with token truncation somewhere\n",
    "    N_DATASIZE = 2_001 # TODO: was 3_000 for non-digraph\n",
    "# \n",
    "    # N_CLUSTERS_MIN = int(0.5 * N_DIMS)\n",
    "    # N_CLUSTERS_MAX = 10 * N_DIMS\n",
    "    # TODO: DEL ME\n",
    "    N_BLOCKS = 6\n",
    "    STRING_SIZE_CUTOFF = 1_000\n",
    "\n",
    "params = cluster_model.InterpParams(\n",
    "\tlattice_params=cluster_model.LatticeParams(\n",
    "\t\ttop_layer_idx = -1,\n",
    "        max_n_parents = 4\n",
    "\t),\n",
    "    # quantization='4bit',\n",
    "\tseed=SEED,\n",
    "    n_datasize=N_DATASIZE,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    model_name=MODEL_NAME,\n",
    "\tmodel_n_dims=N_DIMS,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    string_size_cutoff=STRING_SIZE_CUTOFF,\n",
    "    quantization='4bit'\n",
    ")\n",
    "\n",
    "decomp = cluster_model.Decomposer(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   class GPTNeoXLayer(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.use_parallel_residual = config.use_parallel_residual\\n        self.input_layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\\n        self.post_attention_layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\\n        self.post_attention_dropout = nn.Dropout(config.hidden_dropout)\\n        self.post_mlp_dropout = nn.Dropout(config.hidden_dropout)\\n        self.attention = GPTNeoXAttention(config)\\n        self.mlp = GPTNeoXMLP(config)\\n\\n    def forward(\\n        self,\\n        hidden_states: Optional[torch.FloatTensor],\\n        attention_mask: Optional[torch.FloatTensor] = None,\\n        position_ids: Optional[torch.LongTensor] = None,\\n        head_mask: Optional[torch.FloatTensor] = None,\\n        use_cache: Optional[bool] = False,\\n        layer_past: Optional[Tuple[torch.Tensor]] = None,\\n        output_attentions: Optional[bool] = False,\\n    ):\\n        attention_layer_outputs = self.attention(\\n            self.input_layernorm(hidden_states),\\n            attention_mask=attention_mask,\\n            position_ids=position_ids,\\n            layer_past=layer_past,\\n            head_mask=head_mask,\\n            use_cache=use_cache,\\n            output_attentions=output_attentions,\\n        )\\n        attn_output = attention_layer_outputs[0]  # output_attn: attn_output, present, (attn_weights)\\n        attn_output = self.post_attention_dropout(attn_output)\\n        outputs = list(attention_layer_outputs[1:])\\n\\n        if self.use_parallel_residual:\\n            # pseudocode:\\n            # x = x + attn(ln1(x)) + mlp(ln2(x))\\n            mlp_output = self.mlp(self.post_attention_layernorm(hidden_states))\\n            mlp_output = self.post_mlp_dropout(mlp_output)\\n            hidden_states = mlp_output + attn_output + hidden_states\\n            # Override the present state to be the pre-residual stream addition\\n            outputs[0] = mlp_output + attn_output\\n        else:\\n            raise NotImplementedError\\n            # pseudocode:\\n            # x = x + attn(ln1(x))\\n            # x = x + mlp(ln2(x))\\n            attn_output = attn_output + hidden_states\\n            mlp_output = self.mlp(self.post_attention_layernorm(attn_output))\\n            mlp_output = self.post_mlp_dropout(mlp_output)\\n            hidden_states = mlp_output + attn_output\\n\\n        outputs = tuple(outputs)\\n        if use_cache:\\n            outputs = (hidden_states,) + outputs  # hidden_states, present, (attn_weights)\\n        else:\\n            outputs = (hidden_states,) + outputs[1:]  # hidden_states, (attn_weights)\\n\\n        return outputs\\n\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: make this a bit nicer with hooks\n",
    "# But we are changing to GPTNeoxLayer to\n",
    "\"\"\"\n",
    "   class GPTNeoXLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.use_parallel_residual = config.use_parallel_residual\n",
    "        self.input_layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.post_attention_layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.post_attention_dropout = nn.Dropout(config.hidden_dropout)\n",
    "        self.post_mlp_dropout = nn.Dropout(config.hidden_dropout)\n",
    "        self.attention = GPTNeoXAttention(config)\n",
    "        self.mlp = GPTNeoXMLP(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: Optional[torch.FloatTensor],\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        layer_past: Optional[Tuple[torch.Tensor]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ):\n",
    "        attention_layer_outputs = self.attention(\n",
    "            self.input_layernorm(hidden_states),\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            layer_past=layer_past,\n",
    "            head_mask=head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attn_output = attention_layer_outputs[0]  # output_attn: attn_output, present, (attn_weights)\n",
    "        attn_output = self.post_attention_dropout(attn_output)\n",
    "        outputs = list(attention_layer_outputs[1:])\n",
    "\n",
    "        if self.use_parallel_residual:\n",
    "            # pseudocode:\n",
    "            # x = x + attn(ln1(x)) + mlp(ln2(x))\n",
    "            mlp_output = self.mlp(self.post_attention_layernorm(hidden_states))\n",
    "            mlp_output = self.post_mlp_dropout(mlp_output)\n",
    "            hidden_states = mlp_output + attn_output + hidden_states\n",
    "            # Override the present state to be the pre-residual stream addition\n",
    "            outputs[0] = mlp_output + attn_output\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            # pseudocode:\n",
    "            # x = x + attn(ln1(x))\n",
    "            # x = x + mlp(ln2(x))\n",
    "            attn_output = attn_output + hidden_states\n",
    "            mlp_output = self.mlp(self.post_attention_layernorm(attn_output))\n",
    "            mlp_output = self.post_mlp_dropout(mlp_output)\n",
    "            hidden_states = mlp_output + attn_output\n",
    "\n",
    "        outputs = tuple(outputs)\n",
    "        if use_cache:\n",
    "            outputs = (hidden_states,) + outputs  # hidden_states, present, (attn_weights)\n",
    "        else:\n",
    "            outputs = (hidden_states,) + outputs[1:]  # hidden_states, (attn_weights)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \n",
      "\u001b[0mdecomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mposition_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCausalLMOutputWithPast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCall signature:\u001b[0m  \u001b[0mdecomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m            partial\n",
      "\u001b[0;31mString form:\u001b[0m    \n",
      "functools.partial(<function add_hook_to_module.<locals>.new_forward at 0x7e3dfa5e3eb0>, GPTNeoXFo <...> ntwise_affine=True)\n",
      "           )\n",
      "           (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      "           ))\n",
      "\u001b[0;31mFile:\u001b[0m            ~/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\n",
      "\u001b[0;31mDocstring:\u001b[0m      \n",
      "The [`GPTNeoXForCausalLM`] forward method, overrides the `__call__` special method.\n",
      "\n",
      "<Tip>\n",
      "\n",
      "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
      "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
      "the latter silently ignores them.\n",
      "\n",
      "</Tip>\n",
      "\n",
      "Args:\n",
      "    input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
      "        Indices of input sequence tokens in the vocabulary.\n",
      "\n",
      "        Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
      "        [`PreTrainedTokenizer.__call__`] for details.\n",
      "\n",
      "        [What are input IDs?](../glossary#input-ids)\n",
      "    attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "        Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
      "\n",
      "        - 1 for tokens that are **not masked**,\n",
      "        - 0 for tokens that are **masked**.\n",
      "\n",
      "        [What are attention masks?](../glossary#attention-mask)\n",
      "    position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "        Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
      "        config.n_positions - 1]`.\n",
      "\n",
      "        [What are position IDs?](../glossary#position-ids)\n",
      "    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
      "        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
      "\n",
      "        - 1 indicates the head is **not masked**,\n",
      "        - 0 indicates the head is **masked**.\n",
      "\n",
      "    inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
      "        Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
      "        is useful if you want more control over how to convert *input_ids* indices into associated vectors than the\n",
      "        model's internal embedding lookup matrix.\n",
      "    output_attentions (`bool`, *optional*):\n",
      "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
      "        tensors for more detail.\n",
      "    output_hidden_states (`bool`, *optional*):\n",
      "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
      "        more detail.\n",
      "    return_dict (`bool`, *optional*):\n",
      "        Whether or not to return a [`~file_utils.ModelOutput`] instead of a plain tuple.\n",
      "\n",
      "    past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
      "        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
      "        `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n",
      "        `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`. The two additional tensors are\n",
      "        only required when the model is used as a decoder in a Sequence to Sequence model.\n",
      "\n",
      "        Contains pre-computed hidden-states (key and values in the self-attention blocks that can be used (see\n",
      "        `past_key_values` input) to speed up sequential decoding.\n",
      "\n",
      "        If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
      "        don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
      "        `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
      "    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "        Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n",
      "        `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are\n",
      "        ignored (masked), the loss is only computed for the tokens with labels n `[0, ..., config.vocab_size]`.\n",
      "    use_cache (`bool`, *optional*):\n",
      "        If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
      "        `past_key_values`).\n",
      "\n",
      "\n",
      "    Returns:\n",
      "        [`transformers.modeling_outputs.CausalLMOutputWithPast`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.CausalLMOutputWithPast`] or a tuple of\n",
      "        `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
      "        elements depending on the configuration ([`GPTNeoXConfig`]) and inputs.\n",
      "\n",
      "        - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Language modeling loss (for next-token prediction).\n",
      "        - **logits** (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) -- Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
      "        - **past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`) -- Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
      "          `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n",
      "\n",
      "          Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n",
      "          `past_key_values` input) to speed up sequential decoding.\n",
      "        - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
      "          one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
      "\n",
      "          Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
      "        - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
      "          sequence_length)`.\n",
      "\n",
      "          Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
      "          heads.\n",
      "  \n",
      "\n",
      "    Example:\n",
      "\n",
      "    ```python\n",
      "    >>> from transformers import AutoTokenizer, GPTNeoXForCausalLM, GPTNeoXConfig\n",
      "    >>> import torch\n",
      "\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
      "    >>> config = GPTNeoXConfig.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
      "    >>> config.is_decoder = True\n",
      "    >>> model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/gpt-neox-20b\", config=config)\n",
      "\n",
      "    >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
      "    >>> outputs = model(**inputs)\n",
      "\n",
      "    >>> prediction_logits = outputs.logits\n",
      "    ```\n",
      "\u001b[0;31mClass docstring:\u001b[0m\n",
      "partial(func, *args, **keywords) - new function with partial application\n",
      "of the given arguments and keywords."
     ]
    }
   ],
   "source": [
    "decomp.model[0].forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from cache\n",
      "Got embeddings\n",
      "Using saved correlation for layer 0\n",
      "Using saved correlation for layer 1\n",
      "Using saved correlation for layer 2\n",
      "Using saved correlation for layer 3\n",
      "Using saved correlation for layer 4\n",
      "Using saved correlation for layer 5\n"
     ]
    }
   ],
   "source": [
    "# https://sporco.readthedocs.io/en/latest/examples/dl/cmod.h\n",
    "decomp.load(reload=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Something Like a NMF Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "D_SCALE = 2\n",
    "LAYER = 2\n",
    "\n",
    "model = NMF(n_components=N_DIMS * 2 * D_SCALE, l1_ratio=1, init='random', alpha_W=1, alpha_H=1)\n",
    "# TODO: delete diagonals?\n",
    "B = model.fit(decomp.internal_correlations[LAYER])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to do dictionary learning on the correlation lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.model as smodel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# import SparseAutoencoder, train_autoencoder\n",
    "importlib.reload(smodel)\n",
    "\n",
    "D_SCALE = 3\n",
    "LAYER = 2\n",
    "\n",
    "if False:\n",
    "    # hidden_size = 10  # Number of hidden units\n",
    "    autoencoder = smodel.SparseAutoencoder(N_DIMS * 2, N_DIMS * 2 * D_SCALE, beta=1, lamda=0.001)\n",
    "    \n",
    "    # # Train the autoencoder\n",
    "    dataset = TensorDataset(torch.FloatTensor(decomp.internal_correlations[LAYER]))\n",
    "    smodel.train_autoencoder(autoencoder, dataset, num_epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What's the idea here?\n",
    "\n",
    "The i\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "import numpy as np\n",
    "\n",
    "D_SCALE = 3\n",
    "\n",
    "internal_corrs = np.array(decomp.internal_correlations[LAYER])\n",
    "\n",
    "# Hrmm why would the below effect anything?\n",
    "# for i in range(N_DIMS * 2):\n",
    "#     internal_corrs[i, i] = 0.0\n",
    "\n",
    "d = DictionaryLearning(n_components=N_DIMS * 2 * D_SCALE, alpha=100, fit_algorithm='cd', max_iter=3_000, transform_alpha=5, positive_dict=True)\n",
    "dfit = d.fit(internal_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e3ca3881240>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "a = np.array(dfit.components_[0])\n",
    "a.sort()\n",
    "plot.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfit.transform(internal_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06115304998789689,\n",
       " array([1.        , 0.        , 0.45802488, ..., 0.56535323, 0.75646269,\n",
       "        0.2358806 ]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfit.components_[1].max(), decomp.internal_correlations[LAYER][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4383516 , 0.54469093, 0.43880114, ..., 0.54261433, 0.66154967,\n",
       "        0.33102909]),\n",
       " array([0.43885553, 0.54500787, 0.43904086, ..., 0.54414296, 0.66130015,\n",
       "        0.32963073]),\n",
       " 0.8066932876278969,\n",
       " array([ 2.14876224e-02,  1.76223953e-02,  1.00580212e-01, -3.38107774e-02,\n",
       "        -4.27012532e-02, -8.87312513e-02,  7.94235353e-02,  6.12939324e-02,\n",
       "        -5.07053268e-02,  7.34634308e-02,  1.06779902e-01,  9.46318141e-02,\n",
       "        -7.62439501e-02,  1.17583990e-01,  4.86965965e-02,  9.42712537e-02,\n",
       "         5.26422502e-02,  1.38234717e-03,  1.97326045e-02, -5.31515318e-03,\n",
       "        -1.74065600e-02, -4.08712222e-02,  1.41207139e-02,  1.01808929e-01,\n",
       "         1.47019928e-02,  4.49928121e-02,  7.04316908e-02, -5.21354346e-02,\n",
       "         6.38773643e-02,  1.58208917e-02,  1.07919003e-01,  4.52938226e-02,\n",
       "         5.15131876e-02,  1.13757450e-01,  6.71773751e-02,  9.55582346e-02,\n",
       "         1.81891533e-02,  5.38486439e-02, -6.68131690e-03,  9.25226148e-02,\n",
       "         1.25199303e-01,  6.06040931e-02,  9.50482221e-02, -1.11132935e-02,\n",
       "         8.35934591e-02,  2.84405484e-02,  1.16707408e-01, -2.24510801e-02,\n",
       "         8.43207089e-02,  1.48105615e-01,  7.69137439e-02,  9.11962295e-02,\n",
       "         7.86289867e-02,  1.05851763e-02, -4.34802156e-03,  5.14364578e-02,\n",
       "         9.66538329e-02,  8.85750825e-02,  1.07748315e-01,  1.20893627e-01,\n",
       "        -4.76791989e-02,  1.01827933e-01,  1.33245480e-01,  1.32340787e-01,\n",
       "        -4.13714781e-02,  1.46086432e-01,  6.80801734e-02,  9.52739934e-02,\n",
       "         1.43647828e-01,  2.99060064e-04,  9.03233692e-02,  1.37942167e+01,\n",
       "         1.77821554e-02,  5.31351383e-02,  6.70111214e-02,  7.76395482e-02,\n",
       "         9.37561550e-02,  3.47903841e-02,  1.68926356e-01, -3.84933924e-02,\n",
       "         9.82567152e-03, -5.08883488e-03, -1.29055213e-02, -9.58974286e-02,\n",
       "         1.24029285e-01, -4.78142014e-02,  8.52126078e-02, -6.51108093e-02,\n",
       "         8.16787337e-03,  1.69842473e-01,  7.79404199e-02, -8.32537057e-04,\n",
       "         7.56274773e-02,  6.59708846e-02, -3.58303845e-02,  1.10132988e-01,\n",
       "        -1.68290402e-02, -1.99266724e+00, -6.73368532e-02, -4.03218569e-02,\n",
       "         7.80398572e-02, -4.80687004e-02]),\n",
       " (102,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 100\n",
    "reconstr = None\n",
    "for i in X[idx].nonzero()[0]:\n",
    "    if reconstr is None:\n",
    "        reconstr = dfit.components_[i] * X[idx][i]\n",
    "    else: reconstr += dfit.components_[i] * X[idx][i]\n",
    "\n",
    "diff = np.abs(reconstr - decomp.internal_correlations[LAYER][idx]).sum()\n",
    "reconstr, decomp.internal_correlations[LAYER][idx], diff, X[idx][X[idx].nonzero()[0]], X[idx].nonzero()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Up a \"Concept\" Lattice Using Graph Restrictions\n",
    "\n",
    "> TODO: this is for latter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.graph as graph\n",
    "import networkx as nx\n",
    "\n",
    "LAYER = 3\n",
    "\n",
    "G = graph.di_graph_from_correlations(decomp.internal_correlations[LAYER])\n",
    "MAX_CLIQUE_SIZE = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = graph.sparsify_weighted_digraph(G, degree_upperbound=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXNotImplemented",
     "evalue": "not implemented for directed type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connected\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGG\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/classes/backends.py:148\u001b[0m, in \u001b[0;36m_dispatch.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NetworkXNotImplemented(\n\u001b[1;32m    146\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not implemented by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m             )\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 20:3\u001b[0m, in \u001b[0;36margmap_is_connected_17\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/utils/decorators.py:86\u001b[0m, in \u001b[0;36mnot_implemented_for.<locals>._not_implemented_for\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_not_implemented_for\u001b[39m(g):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (mval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_multigraph()) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     84\u001b[0m         dval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_directed()\n\u001b[1;32m     85\u001b[0m     ):\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXNotImplemented(errmsg)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m: not implemented for directed type"
     ]
    }
   ],
   "source": [
    "nx.is_connected(GG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7804636816254003,\n",
       " 0.7813018624377651,\n",
       " 0.7817276582904464,\n",
       " 0.7819791125341559,\n",
       " 0.782213803161618,\n",
       " 0.7823479120915964,\n",
       " 0.7833436708966859,\n",
       " 0.7835247179521566,\n",
       " 0.7869411429433557,\n",
       " 0.7878128509882152,\n",
       " 0.7910716979866896,\n",
       " 0.7912192178096659,\n",
       " 0.79138014852564,\n",
       " 0.7920272241127856,\n",
       " 0.7953866528087439,\n",
       " 0.7988600740951838,\n",
       " 0.80074430456138,\n",
       " 0.8030811526662531,\n",
       " 0.8040802641945921,\n",
       " 0.8048480378187183,\n",
       " 0.8060449600187752,\n",
       " 0.8073391111930666,\n",
       " 0.8090758218362866,\n",
       " 0.8101017551506211,\n",
       " 0.8137763398320286,\n",
       " 0.8160193116859169,\n",
       " 0.8231539067607664,\n",
       " 0.8258427908068329,\n",
       " 0.8313479623824451,\n",
       " 0.8318173436373695,\n",
       " 0.8386602517895161,\n",
       " 0.8412820813705932,\n",
       " 0.8418151643672573,\n",
       " 0.8424857090171491,\n",
       " 0.8467771947764572,\n",
       " 0.847658960991065,\n",
       " 0.8497845875312222,\n",
       " 0.8533854123011416,\n",
       " 0.8545387490989557,\n",
       " 0.8598863426818433,\n",
       " 0.8603825457227633,\n",
       " 0.8661056443095905,\n",
       " 0.8667191926642416,\n",
       " 0.8674266172698775,\n",
       " 0.8727473890667695,\n",
       " 0.8749501282416643,\n",
       " 0.8766365480361423,\n",
       " 0.8823227666672254,\n",
       " 0.9292005431411664,\n",
       " 0.962989288049218,\n",
       " 0.973047457797596]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = []\n",
    "for j in range(1_024):\n",
    "    c = GG.get_edge_data(0, j)\n",
    "    if c is not None:\n",
    "        cc.append(c['weight'])\n",
    "cc.sort()\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mnext\u001b[39m(\u001b[43mi\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7cfd8fd7beb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GG.get_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from '/home/lev/code/research/ai/lattice_cluster_paths/src/utils.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src.utils as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "decomp.tune_clique((0.0, clique), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# test_at = 100\n",
    "# GG = graph.sparsify_weighted_graph(G, degree_upperbound=test_at)\n",
    "\n",
    "# cliques = []\n",
    "\n",
    "# for node in range(N_DIMS * 2):\n",
    "#     if node % 50 == 0:\n",
    "#         print(\"On node\", node)\n",
    "#     c_it = nx.find_cliques(GG, nodes=[node])\n",
    "#     c_in_curr = []\n",
    "#     for c in c_it:\n",
    "#         c_in_curr.append(c)\n",
    "#         if len(c_in_curr) > 50:\n",
    "#             break\n",
    "#     cliques += c_in_curr\n",
    "#         # if len(cliques) > 10_000:\n",
    "#         #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.50411391, ..., 0.41980654, 0.47819793,\n",
       "        0.52677501],\n",
       "       [0.        , 1.        , 0.51517917, ..., 0.56102004, 0.50169823,\n",
       "        0.55460722],\n",
       "       [0.50411391, 0.51517917, 1.        , ..., 0.47680901, 0.5166343 ,\n",
       "        0.52601947],\n",
       "       ...,\n",
       "       [0.41980654, 0.56102004, 0.47680901, ..., 1.        , 0.40289529,\n",
       "        0.57754201],\n",
       "       [0.47819793, 0.50169823, 0.5166343 , ..., 0.40289529, 1.        ,\n",
       "        0.        ],\n",
       "       [0.52677501, 0.55460722, 0.52601947, ..., 0.57754201, 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp.internal_correlations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT CLIQUES WITH LENGTH [9, 9, 10] [(23.79445227225935, [2, 771, 128, 217, 389, 593, 657, 661, 785]), (25.24844098956523, [2, 771, 128, 217, 389, 593, 657, 687, 936]), (29.81072255571707, [2, 771, 128, 217, 389, 593, 657, 687, 785, 613])]\n",
      "Got tuned clique [0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6]\n",
      "Got tuned clique [0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6, 0.0]\n",
      "Got tuned clique [0.0, 0.8, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0]\n",
      "Finished for neuron 2 2\n"
     ]
    }
   ],
   "source": [
    "import src.decorrelate as decc\n",
    "import src.kernel as kernel\n",
    "importlib.reload(decc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(kernel)\n",
    "\n",
    "LAYER = 2\n",
    "NEURON = 2\n",
    "\n",
    "# TODO: we **need** to do something like curr-clique removal so we get more interesting cliques...\n",
    "# Also the per-neuron thing makes no sense...\n",
    "\n",
    "# TODO: change size of subset??\n",
    "decomp.scores_for_neuron(LAYER, NEURON, degree_upperbound=400, n_features_per_neuron=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
