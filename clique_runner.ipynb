{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating decomposer with parameter data hash cache/data-05e441406567ff2be4dc9c51e891918f5747747a/start.pkl\n",
      "Creating decomposer with parameter lattice hash cache/correlation-d2e9a74f412a5e15e0fcde6056db6a751baf0149/start.pkl\n",
      "Created dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished and saving to file\n",
      "\n",
      "Got embeddings\n",
      "Computing internal correlations for layer 0\n",
      "(1024, 507306) (1024, 507306)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_225415/1769244142.py\", line 41, in <module>\n",
      "    decomp.load(reload=True)\n",
      "  File \"/home/lev/code/research/ai/lattice_cluster_paths/src/decorrelate.py\", line 251, in load\n",
      "    self.model, self.dataset, self.layers, params=self.params, use_save=not reload)\n",
      "  File \"/home/lev/code/research/ai/lattice_cluster_paths/src/decorrelate.py\", line 194, in correlate_internal_layer\n",
      "  File \"/home/lev/code/research/ai/lattice_cluster_paths/src/utils.py\", line 292, in pairwise_correlation_metric\n",
      "    return pairwise_signaling(A, B)\n",
      "  File \"/home/lev/code/research/ai/lattice_cluster_paths/src/utils.py\", line 249, in pairwise_signaling\n",
      "    signaling[i, j] = p_i_and_j.sum() / p_i_j_min\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/numpy/core/_methods.py\", line 49, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/lev/.local/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import src.decorrelate as cluster_model\n",
    "MODEL_NAME = 'EleutherAI/pythia-70m'\n",
    "DATASET_NAME = 'NeelNanda/pile-10k'\n",
    "\n",
    "N_DIMS = 512\n",
    "SEED = 69_420\n",
    " \n",
    "DEBUG = False\n",
    " \n",
    "if DEBUG:\n",
    "    N_DATASIZE = 300\n",
    "    N_BLOCKS = 12\n",
    "    STRING_SIZE_CUTOFF = 200\n",
    "else:\n",
    "    # It gets killed aroun 1_800 idk why. Maybe we have a problem with token truncation somewhere\n",
    "    N_DATASIZE = 3_000\n",
    "# \n",
    "    # N_CLUSTERS_MIN = int(0.5 * N_DIMS)\n",
    "    # N_CLUSTERS_MAX = 10 * N_DIMS\n",
    "    # TODO: DEL ME\n",
    "    N_BLOCKS = 6\n",
    "    STRING_SIZE_CUTOFF = 1_200\n",
    "\n",
    "params = cluster_model.InterpParams(\n",
    "\tlattice_params=cluster_model.LatticeParams(\n",
    "\t\ttop_layer_idx = -1,\n",
    "        max_n_parents = 4\n",
    "\t),\n",
    "    # quantization='4bit',\n",
    "\tseed=SEED,\n",
    "    n_datasize=N_DATASIZE,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    model_name=MODEL_NAME,\n",
    "\tmodel_n_dims=N_DIMS,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    string_size_cutoff=STRING_SIZE_CUTOFF,\n",
    "    quantization='4bit'\n",
    ")\n",
    "\n",
    "decomp = cluster_model.Decomposer(params)\n",
    "decomp.load(reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets just look at the highest cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp.internal_correlations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Up a \"Concept\" Lattice Using Graph Restrictions\n",
    "\n",
    "> TODO: this is for latter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.graph as graph\n",
    "import networkx as nx\n",
    "\n",
    "LAYER = 3\n",
    "\n",
    "G = graph.graph_from_correlations(decomp.internal_correlations[LAYER])\n",
    "MAX_CLIQUE_SIZE = 1_000\n",
    "\n",
    "GG = graph.sparsify_weighted_graph(G, degree_upperbound=400)\n",
    "i = nx.find_cliques(GG)\n",
    "clique = next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.utils as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# decomp.tune_clique((0.0, clique), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# test_at = 100\n",
    "# GG = graph.sparsify_weighted_graph(G, degree_upperbound=test_at)\n",
    "\n",
    "# cliques = []\n",
    "\n",
    "# for node in range(N_DIMS * 2):\n",
    "#     if node % 50 == 0:\n",
    "#         print(\"On node\", node)\n",
    "#     c_it = nx.find_cliques(GG, nodes=[node])\n",
    "#     c_in_curr = []\n",
    "#     for c in c_it:\n",
    "#         c_in_curr.append(c)\n",
    "#         if len(c_in_curr) > 50:\n",
    "#             break\n",
    "#     cliques += c_in_curr\n",
    "#         # if len(cliques) > 10_000:\n",
    "#         #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp.internal_correlations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.decorrelate as decc\n",
    "import src.kernel as kernel\n",
    "importlib.reload(decc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(kernel)\n",
    "\n",
    "LAYER = 2\n",
    "NEURON = 20\n",
    "\n",
    "# TODO: we **need** to do something like curr-clique removal so we get more interesting cliques...\n",
    "# Also the per-neuron thing makes no sense...\n",
    "decomp.scores_for_neuron(LAYER, NEURON, degree_upperbound=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
